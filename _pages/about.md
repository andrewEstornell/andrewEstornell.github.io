---
permalink: /
title: "Research Interests and Background"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


I am a fifth-year PhD student studying Computer Science at Washington University in St Louis with my advisors Yevgeniy Vorobeychik and Sanmay Das. 
My research interests fall broadly within the fields of Algorithmic Fairness, Adversarial Machine Learning, Optimization, Game Theory, and Strategic Classification.
I enjoy working on problems which can be approached from both theoretical and applied perspectives, especially those which make use of Machine Learning in unconventional or innovative ways, and those which involve interactions between multiple strategic agents. 

Recently my thesis work has focused on Algorithmic Fairness and Strategic Classification, with an emphasis on how these two fields relate to one another. 
When the decisions of machine learning models are consequential enough to merit considerations of fairness (e.g. in automated lending), these decisions are also consequential enough to incentive individuals to behave strategically. 
As such, Algorithmic Fairness and Strategic Classification are fundamentally intertwined; the consideration of strategic behavior is paramount to successful deployment of fair models in practice. To this end, I have been working on the development of machine learning models which are both fair and robust to manipulation by strategic agents. 

Outside of my thesis work I have recently been pursuing Adversarial Machine Learning in the context of robustness for image recognition systems, as well as  Multi-Agent Deep Reinforcement Learning in the context of ride-sharing. 


# Publications
------
### Published

**[1] Popularizing Fairness: Group Fairness and Individual Welfare.** Andrew Estornell, Sanmay Das, Brendan Juba, Yevgeniy Vorobeychik. Conference on Artificial Intelligence (AAAI) 2023. [[link]](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SSW02WEAAAAJ&citation_for_view=SSW02WEAAAAJ:UeHWp8X0CEIC) [[pdf]](/assets/pdfs/PopularFairness2023.pdf)

**[2] Location Spoofing Attacks on Autonomous Fleets.** Jinghan Yang, Andrew Estornell, Yevgeniy Vorobeychik. Conference on Vehicle Security and Privacy (VehicleSec) 2023 \[TO APPEAR\]

**[3] Manipulating Elections by Changing Voter Perceptions.** Junlin Wu, Andrew Estornell, Lecheng Kong, Yevgeniy Vorobeychik. International Joint Conference on Artificial Intelligence (IJCAI) 2022. [[link]](https://arxiv.org/pdf/2205.00102.pdf) [[pdf]](/assets/pdfs/ElectionControl2022.pdf)

**[4]  Incentivizing Truthfulness Through Audits in Strategic Classification.** Andrew Estornell, Sanmay Das, Yevgeniy Vorobeychik. Conference on Artificial Intelligence (AAAI) 2021. [[link]](https://ojs.aaai.org/index.php/AAAI/article/view/16674) [[pdf]](/assets/pdfs/Audits2021.pdf)


**[5] Election Control by Manipulating Issue Significance.** Andrew Estornell, Sanmay Das, Edith Elkind, Yevgeniy Vorobeychik.  Conference on Uncertainty in Artificial Intelligence (UAI) 2020. [[link]](https://proceedings.mlr.press/v124/estornell20a.html) [[pdf]](/assets/pdfs/ElectionControl2020.pdf)


**[6] Deception Through Half-Truths.** Andrew Estornell, Sanmay Das, Yevgeniy Vorobeychik. Conference on Artificial Intelligence (AAAI) 2020. [[link]](https://ojs.aaai.org/index.php/AAAI/article/view/6570) [[pdf]](/assets/pdfs/Deception2020.pdf)

**[7] PBW Deformations of Quadratic Monomial Algebras.** Andrew Estornell, Zachary Cline, Chelsea Walton, Matthew Wynne.  Communications in Algebra 2019. [[link]](https://www.tandfonline.com/doi/full/10.1080/00927872.2018.1536757?casa_token=TuCNA221xeEAAAAA:St_MqmqvdsrE0qoSf_ku_7kvrOTZ5zoXXcdvRY6inE3c5d09eqxkmoTFg1opAkfhTf3baPFiIqqHxEU) [[pdf]](/assets/pdfs/PBW2019.pdf)


### Pre-Prints

**[8] Unfairness Despite Awareness: Group-Fair Classification with Strategic Agents.** Andrew Estornell, Sanmay Das, Yang Liu, Yevgeniy Vorobeychik, 2022. Appeared at, Learning with Strategic Agents Workshop **best paper award** (LSA at AAMAS 2022) and Strategic Machine Learning Workshop (StratML at NeurIPS 2021). [[link]](https://arxiv.org/pdf/2112.02746.pdf) [[pdf]](/assets/pdfs/FairnessReversal2022.pdf)


### Under Review

**[9] Incentivizing Recourse through Auditing in Strategic Classification.** Andrew Estornell, Sanmay Das, Yang Liu, Yatong Chen, Yevgeniy Vorobeychik. 2023. 

**[10] Which Features are the Fairest of them All? The Impact of Features Used by Algorithms on Perceptions of Fairness.** Andrew Estornell, Tina Zhang, Sanmay Das, Chien-Ju Ho, Brendan Juba, Yevgeniy Vorobeychik. 2023.

**[11] Individual Impacts of Group Fairness in Machine Learning.** Andrew Estornell, Sanmay Das, Patrick Fowler, Brendan Juba, Pauline Kim, Yevgeniy Vorobeychik, 2022. 




